[
  {
    "capabilities": {
      "family": "gpt-5-mini",
      "limits": {
        "max_context_window_tokens": 264000,
        "max_output_tokens": 64000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "structured_outputs": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-5-mini",
    "model_picker_category": "lightweight",
    "model_picker_enabled": true,
    "name": "GPT-5 mini",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest GPT-5 mini model from OpenAI. [Learn more about how GitHub Copilot serves GPT-5 mini](https://gh.io/copilot-openai)."
    },
    "preview": false,
    "supported_endpoints": ["/chat/completions", "/responses"],
    "vendor": "Azure OpenAI",
    "version": "gpt-5-mini"
  },
  {
    "capabilities": {
      "family": "gpt-5",
      "limits": {
        "max_context_window_tokens": 400000,
        "max_output_tokens": 128000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "structured_outputs": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-5",
    "model_picker_category": "versatile",
    "model_picker_enabled": true,
    "name": "GPT-5",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest GPT-5 model from OpenAI. [Learn more about how GitHub Copilot serves GPT-5](https://gh.io/copilot-openai)."
    },
    "preview": false,
    "supported_endpoints": ["/chat/completions", "/responses"],
    "vendor": "Azure OpenAI",
    "version": "gpt-5"
  },
  {
    "capabilities": {
      "family": "gpt-4o-mini",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 64000
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4o-mini-2024-07-18",
    "model_picker_enabled": false,
    "name": "GPT-4o mini",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4o-mini-2024-07-18"
  },
  {
    "capabilities": {
      "family": "gpt-4o",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 16384,
        "max_prompt_tokens": 64000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4o-2024-11-20",
    "model_picker_enabled": false,
    "name": "GPT-4o",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4o-2024-11-20"
  },
  {
    "capabilities": {
      "family": "gpt-4o",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 16384,
        "max_prompt_tokens": 64000
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4o-2024-08-06",
    "model_picker_enabled": false,
    "name": "GPT-4o",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4o-2024-08-06"
  },
  {
    "capabilities": {
      "family": "grok-code",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 64000,
        "max_prompt_tokens": 128000
      },
      "object": "model_capabilities",
      "supports": {
        "streaming": true,
        "structured_outputs": true,
        "tool_calls": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "grok-code-fast-1",
    "model_picker_category": "lightweight",
    "model_picker_enabled": true,
    "name": "Grok Code Fast 1",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest Grok Code Fast 1 model from xAI. If enabled, you instruct GitHub Copilot to send data to xAI Grok Code Fast 1. [Learn more about how GitHub Copilot serves Grok Code Fast 1](https://docs.github.com/en/copilot/reference/ai-models/model-hosting#xai-models). During launch week, [promotional pricing is 0x](https://gh.io/copilot-grok-code-promo)."
    },
    "preview": false,
    "vendor": "xAI",
    "version": "grok-code-fast-1"
  },
  {
    "capabilities": {
      "family": "gpt-5.1",
      "limits": {
        "max_context_window_tokens": 264000,
        "max_output_tokens": 64000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "structured_outputs": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-5.1",
    "model_picker_category": "versatile",
    "model_picker_enabled": true,
    "name": "GPT-5.1",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest GPT-5.1 model from OpenAI. [Learn more about how GitHub Copilot serves GPT-5.1](https://gh.io/copilot-openai)."
    },
    "preview": false,
    "supported_endpoints": ["/chat/completions", "/responses"],
    "vendor": "OpenAI",
    "version": "gpt-5.1"
  },
  {
    "capabilities": {
      "family": "gpt-5.1-codex",
      "limits": {
        "max_context_window_tokens": 400000,
        "max_output_tokens": 128000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "structured_outputs": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-5.1-codex",
    "model_picker_category": "powerful",
    "model_picker_enabled": true,
    "name": "GPT-5.1-Codex",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest GPT-5.1-Codex model from OpenAI. [Learn more about how GitHub Copilot serves GPT-5.1-Codex](https://gh.io/copilot-openai)."
    },
    "preview": false,
    "supported_endpoints": ["/responses"],
    "vendor": "OpenAI",
    "version": "gpt-5.1-codex"
  },
  {
    "capabilities": {
      "family": "gpt-5.1-codex-max",
      "limits": {
        "max_context_window_tokens": 400000,
        "max_output_tokens": 128000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "structured_outputs": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-5.1-codex-max",
    "model_picker_category": "powerful",
    "model_picker_enabled": true,
    "name": "GPT-5.1-Codex-Max",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest GPT-5.1-Codex-Max model from OpenAI. [Learn more about how GitHub Copilot serves GPT-5.1-Codex-Max](https://gh.io/copilot-openai)."
    },
    "preview": false,
    "supported_endpoints": ["/responses"],
    "vendor": "OpenAI",
    "version": "gpt-5.1-codex-max"
  },
  {
    "capabilities": {
      "family": "text-embedding-3-small",
      "limits": { "max_inputs": 512 },
      "object": "model_capabilities",
      "supports": { "dimensions": true },
      "tokenizer": "cl100k_base",
      "type": "embeddings"
    },
    "id": "text-embedding-3-small",
    "model_picker_enabled": false,
    "name": "Embedding V3 small",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "text-embedding-3-small"
  },
  {
    "capabilities": {
      "family": "text-embedding-3-small",
      "object": "model_capabilities",
      "supports": { "dimensions": true },
      "tokenizer": "cl100k_base",
      "type": "embeddings"
    },
    "id": "text-embedding-3-small-inference",
    "model_picker_enabled": false,
    "name": "Embedding V3 small (Inference)",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "text-embedding-3-small"
  },
  {
    "capabilities": {
      "family": "claude-sonnet-4",
      "limits": {
        "max_context_window_tokens": 216000,
        "max_output_tokens": 16000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 5,
          "supported_media_types": ["image/jpeg", "image/png", "image/webp"]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "max_thinking_budget": 32000,
        "min_thinking_budget": 1024,
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "claude-sonnet-4",
    "model_picker_category": "versatile",
    "model_picker_enabled": true,
    "name": "Claude Sonnet 4",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest Claude Sonnet 4 model from Anthropic. [Learn more about how GitHub Copilot serves Claude Sonnet 4](https://docs.github.com/en/copilot/using-github-copilot/ai-models/using-claude-sonnet-in-github-copilot)."
    },
    "preview": false,
    "supported_endpoints": ["/chat/completions"],
    "vendor": "Anthropic",
    "version": "claude-sonnet-4"
  },
  {
    "capabilities": {
      "family": "claude-sonnet-4.5",
      "limits": {
        "max_context_window_tokens": 144000,
        "max_output_tokens": 16000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 5,
          "supported_media_types": ["image/jpeg", "image/png", "image/webp"]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "max_thinking_budget": 32000,
        "min_thinking_budget": 1024,
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "claude-sonnet-4.5",
    "model_picker_category": "versatile",
    "model_picker_enabled": true,
    "name": "Claude Sonnet 4.5",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest Claude Sonnet 4.5 model from Anthropic. [Learn more about how GitHub Copilot serves Claude Sonnet 4.5](https://docs.github.com/en/copilot/using-github-copilot/ai-models/using-claude-sonnet-in-github-copilot)."
    },
    "preview": false,
    "supported_endpoints": ["/chat/completions"],
    "vendor": "Anthropic",
    "version": "claude-sonnet-4.5"
  },
  {
    "capabilities": {
      "family": "claude-opus-4.5",
      "limits": {
        "max_context_window_tokens": 160000,
        "max_output_tokens": 16000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 5,
          "supported_media_types": ["image/jpeg", "image/png", "image/webp"]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "max_thinking_budget": 32000,
        "min_thinking_budget": 1024,
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "claude-opus-4.5",
    "model_picker_category": "powerful",
    "model_picker_enabled": true,
    "name": "Claude Opus 4.5",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest Claude Opus 4.5 model from Anthropic. [Learn more about how GitHub Copilot serves Claude Opus 4.5](https://gh.io/copilot-anthropic)."
    },
    "preview": false,
    "supported_endpoints": ["/chat/completions"],
    "vendor": "Anthropic",
    "version": "claude-opus-4.5"
  },
  {
    "capabilities": {
      "family": "claude-haiku-4.5",
      "limits": {
        "max_context_window_tokens": 144000,
        "max_output_tokens": 16000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 5,
          "supported_media_types": ["image/jpeg", "image/png", "image/webp"]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "max_thinking_budget": 32000,
        "min_thinking_budget": 1024,
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "claude-haiku-4.5",
    "model_picker_category": "versatile",
    "model_picker_enabled": true,
    "name": "Claude Haiku 4.5",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest Claude Haiku 4.5 model from Anthropic. [Learn more about how GitHub Copilot serves Claude Haiku 4.5](https://gh.io/copilot-anthropic)."
    },
    "preview": false,
    "supported_endpoints": ["/chat/completions"],
    "vendor": "Anthropic",
    "version": "claude-haiku-4.5"
  },
  {
    "capabilities": {
      "family": "gemini-2.5-pro",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 64000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/heic",
            "image/heif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "max_thinking_budget": 32768,
        "min_thinking_budget": 128,
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gemini-2.5-pro",
    "model_picker_category": "powerful",
    "model_picker_enabled": true,
    "name": "Gemini 2.5 Pro",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest Gemini 2.5 Pro model from Google. [Learn more about how GitHub Copilot serves Gemini 2.5 Pro](https://docs.github.com/en/copilot/using-github-copilot/ai-models/choosing-the-right-ai-model-for-your-task#gemini-25-pro)."
    },
    "preview": false,
    "vendor": "Google",
    "version": "gemini-2.5-pro"
  },
  {
    "capabilities": {
      "family": "gpt-4.1",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 16384,
        "max_prompt_tokens": 64000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "structured_outputs": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4.1-2025-04-14",
    "model_picker_enabled": false,
    "name": "GPT-4.1",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest GPT-4.1 model from OpenAI. [Learn more about how GitHub Copilot serves GPT-4.1](https://docs.github.com/en/copilot/using-github-copilot/ai-models/choosing-the-right-ai-model-for-your-task#gpt-41)."
    },
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4.1-2025-04-14"
  },
  {
    "capabilities": {
      "family": "gpt-5.2",
      "limits": {
        "max_context_window_tokens": 264000,
        "max_output_tokens": 64000,
        "max_prompt_tokens": 128000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "structured_outputs": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-5.2",
    "model_picker_category": "versatile",
    "model_picker_enabled": true,
    "name": "GPT-5.2",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest GPT-5.2 model from OpenAI. [Learn more about how GitHub Copilot serves GPT-5.2](https://gh.io/copilot-openai)."
    },
    "preview": false,
    "supported_endpoints": ["/chat/completions", "/responses"],
    "vendor": "OpenAI",
    "version": "gpt-5.2"
  },
  {
    "capabilities": {
      "family": "gpt-3.5-turbo",
      "limits": {
        "max_context_window_tokens": 16384,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 16384
      },
      "object": "model_capabilities",
      "supports": { "streaming": true, "tool_calls": true },
      "tokenizer": "cl100k_base",
      "type": "chat"
    },
    "id": "gpt-3.5-turbo-0613",
    "model_picker_enabled": false,
    "name": "GPT 3.5 Turbo",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-3.5-turbo-0613"
  },
  {
    "capabilities": {
      "family": "gpt-4",
      "limits": {
        "max_context_window_tokens": 32768,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 32768
      },
      "object": "model_capabilities",
      "supports": { "streaming": true, "tool_calls": true },
      "tokenizer": "cl100k_base",
      "type": "chat"
    },
    "id": "gpt-4",
    "model_picker_enabled": false,
    "name": "GPT 4",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4-0613"
  },
  {
    "capabilities": {
      "family": "gpt-4",
      "limits": {
        "max_context_window_tokens": 32768,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 32768
      },
      "object": "model_capabilities",
      "supports": { "streaming": true, "tool_calls": true },
      "tokenizer": "cl100k_base",
      "type": "chat"
    },
    "id": "gpt-4-0613",
    "model_picker_enabled": false,
    "name": "GPT 4",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4-0613"
  },
  {
    "capabilities": {
      "family": "gpt-4o",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 64000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4o-2024-05-13",
    "model_picker_enabled": false,
    "name": "GPT-4o",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4o-2024-05-13"
  },
  {
    "capabilities": {
      "family": "gpt-4o",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 64000
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4-o-preview",
    "model_picker_enabled": false,
    "name": "GPT-4o",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4o-2024-05-13"
  },
  {
    "capabilities": {
      "family": "gpt-4.1",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 16384,
        "max_prompt_tokens": 64000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "structured_outputs": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4.1",
    "model_picker_category": "versatile",
    "model_picker_enabled": true,
    "name": "GPT-4.1",
    "object": "model",
    "policy": {
      "state": "enabled",
      "terms": "Enable access to the latest GPT-4.1 model from OpenAI. [Learn more about how GitHub Copilot serves GPT-4.1](https://docs.github.com/en/copilot/using-github-copilot/ai-models/choosing-the-right-ai-model-for-your-task#gpt-41)."
    },
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4.1-2025-04-14"
  },
  {
    "capabilities": {
      "family": "gpt-3.5-turbo",
      "limits": {
        "max_context_window_tokens": 16384,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 16384
      },
      "object": "model_capabilities",
      "supports": { "streaming": true, "tool_calls": true },
      "tokenizer": "cl100k_base",
      "type": "chat"
    },
    "id": "gpt-3.5-turbo",
    "model_picker_enabled": false,
    "name": "GPT 3.5 Turbo",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-3.5-turbo-0613"
  },
  {
    "capabilities": {
      "family": "gpt-4o-mini",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 64000
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4o-mini",
    "model_picker_enabled": false,
    "name": "GPT-4o mini",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4o-mini-2024-07-18"
  },
  {
    "capabilities": {
      "family": "gpt-4",
      "limits": {
        "max_context_window_tokens": 32768,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 32768
      },
      "object": "model_capabilities",
      "supports": { "streaming": true, "tool_calls": true },
      "tokenizer": "cl100k_base",
      "type": "chat"
    },
    "id": "gpt-4",
    "model_picker_enabled": false,
    "name": "GPT 4",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4-0613"
  },
  {
    "capabilities": {
      "family": "gpt-4o",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 64000,
        "vision": {
          "max_prompt_image_size": 3145728,
          "max_prompt_images": 1,
          "supported_media_types": [
            "image/jpeg",
            "image/png",
            "image/webp",
            "image/gif"
          ]
        }
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true,
        "vision": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4o",
    "model_picker_category": "versatile",
    "model_picker_enabled": true,
    "name": "GPT-4o",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4o-2024-11-20"
  },
  {
    "capabilities": {
      "family": "gpt-4o",
      "limits": {
        "max_context_window_tokens": 128000,
        "max_output_tokens": 4096,
        "max_prompt_tokens": 64000
      },
      "object": "model_capabilities",
      "supports": {
        "parallel_tool_calls": true,
        "streaming": true,
        "tool_calls": true
      },
      "tokenizer": "o200k_base",
      "type": "chat"
    },
    "id": "gpt-4-o-preview",
    "model_picker_enabled": false,
    "name": "GPT-4o",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "gpt-4o-2024-05-13"
  },
  {
    "capabilities": {
      "family": "text-embedding-ada-002",
      "limits": { "max_inputs": 512 },
      "object": "model_capabilities",
      "supports": {},
      "tokenizer": "cl100k_base",
      "type": "embeddings"
    },
    "id": "text-embedding-ada-002",
    "model_picker_enabled": false,
    "name": "Embedding V2 Ada",
    "object": "model",
    "preview": false,
    "vendor": "Azure OpenAI",
    "version": "text-embedding-3-small"
  }
]
